{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwRk9X2P3UUm",
        "outputId": "9a572aad-470b-4d43-f672-6c1787c9d72e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WCSB_Supply_Demand'...\n",
            "remote: Enumerating objects: 198, done.\u001b[K\n",
            "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (178/178), done.\u001b[K\n",
            "remote: Total 198 (delta 58), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (198/198), 5.70 MiB | 3.43 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "\n",
            "üì¶ Processing 2010...\n",
            "‚úÖ Recovery methods seen: ['Commercial' 'Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery'\n",
            " 'Experimental' 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2011...\n",
            "‚úÖ Recovery methods seen: ['Commercial' 'Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery'\n",
            " 'Experimental' 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2012...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Experimental'\n",
            " 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2013...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Experimental'\n",
            " 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2014...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Experimental'\n",
            " 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2015...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Experimental'\n",
            " 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2016...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2017...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Experimental'\n",
            " 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2018...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Experimental'\n",
            " 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2019...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Experimental'\n",
            " 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2020...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2021...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2022...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2023...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2024...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Primary' 'Total ']\n",
            "\n",
            "üì¶ Processing 2025...\n",
            "‚úÖ Recovery methods seen: ['Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery' 'Primary' 'Total ']\n",
            "\n",
            "üéØ Final shape: (33007, 7)\n",
            "üìÖ Dates: 2010-01-01 00:00:00 ‚Üí 2025-03-01 00:00:00\n",
            "üîç Recovery Methods: ['Commercial' 'Commercial-CSS' 'Commercial-SAGD' 'Enhanced Recovery'\n",
            " 'Experimental' 'Primary']\n",
            "‚úÖ File pushed to GitHub: https://github.com/blainehodder/WCSB_Supply_Demand/blob/main/clean_data/st53/st53_cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "# --- Clone repo to get push utility ---\n",
        "!git clone https://github.com/blainehodder/WCSB_Supply_Demand.git\n",
        "import sys\n",
        "sys.path.append(\"/content/WCSB_Supply_Demand\")\n",
        "\n",
        "# --- Import push function ---\n",
        "from utils.github_commit import push_df_to_github\n",
        "\n",
        "# --- Core imports ---\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "# --- GitHub token (REPLACE WITH YOURS) ---\n",
        "os.environ[\"GITHUB_TOKEN\"] = \"ghp_####\"\n",
        "\n",
        "# --- CONFIG ---\n",
        "years = list(range(2010, 2026))\n",
        "base_url = \"https://raw.githubusercontent.com/blainehodder/WCSB_Supply_Demand/main/raw_data/st53/ST53_{}.xls\"\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for year in years:\n",
        "    try:\n",
        "        print(f\"\\nüì¶ Processing {year}...\")\n",
        "        url = base_url.format(year)\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Load XLS and parse BITUMEN sheet\n",
        "        xls = pd.ExcelFile(BytesIO(response.content))\n",
        "        df = pd.read_excel(xls, sheet_name=\"BITUMEN\", header=None)\n",
        "\n",
        "        # Detect the header row dynamically\n",
        "        header_idx = df[df.apply(lambda row: row.astype(str).str.contains(\"Operator\", case=False).any(), axis=1)].index[0]\n",
        "        df.columns = df.iloc[header_idx]\n",
        "        df = df.iloc[header_idx + 1:].reset_index(drop=True)\n",
        "\n",
        "        # Normalize column names\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        # Skip if recovery method is completely missing\n",
        "        if \"Recovery Method\" not in df.columns:\n",
        "            print(f\"‚ö†Ô∏è No 'recovery method' in {year}\")\n",
        "            continue\n",
        "\n",
        "        print(\"‚úÖ Recovery methods seen:\", df[\"Recovery Method\"].dropna().unique()[:10])\n",
        "\n",
        "        # Melt to long format\n",
        "        id_cols = ['Operator', 'Scheme Name', 'Area', 'Approval Number', 'Recovery Method']\n",
        "        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                  'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "\n",
        "        # Coerce production values\n",
        "        for m in months:\n",
        "            if m in df.columns:\n",
        "                df[m] = pd.to_numeric(df[m], errors=\"coerce\")\n",
        "\n",
        "        melted = df.melt(id_vars=id_cols, value_vars=months,\n",
        "                         var_name=\"Month\", value_name=\"Bitumen Production\")\n",
        "\n",
        "        melted[\"Year\"] = year\n",
        "        melted[\"Month_Num\"] = melted[\"Month\"].map({\n",
        "            'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "            'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
        "        })\n",
        "        melted[\"Date\"] = pd.to_datetime(dict(year=melted[\"Year\"], month=melted[\"Month_Num\"], day=1))\n",
        "\n",
        "        # Clean and keep valid records\n",
        "        melted[\"Bitumen Production\"] = pd.to_numeric(melted[\"Bitumen Production\"], errors=\"coerce\")\n",
        "        cleaned = melted[['Date'] + id_cols + ['Bitumen Production']].copy()\n",
        "        cleaned = cleaned.dropna(subset=[\"Bitumen Production\", \"Operator\", \"Recovery Method\"])\n",
        "\n",
        "        all_data.append(cleaned)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed {year}: {e}\")\n",
        "\n",
        "# Final concat and push\n",
        "if not all_data:\n",
        "    raise ValueError(\"No data loaded from any year.\")\n",
        "\n",
        "final_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(f\"\\nüéØ Final shape: {final_df.shape}\")\n",
        "print(f\"üìÖ Dates: {final_df['Date'].min()} ‚Üí {final_df['Date'].max()}\")\n",
        "print(f\"üîç Recovery Methods: {final_df['Recovery Method'].dropna().unique()}\")\n",
        "\n",
        "# --- Push to GitHub ---\n",
        "push_df_to_github(\n",
        "    df=final_df,\n",
        "    user=\"blainehodder\",\n",
        "    repo=\"WCSB_Supply_Demand\",\n",
        "    path=\"clean_data/st53/st53_cleaned.csv\",\n",
        "    commit_message=\"Full ST53 cleaned with Primary rows preserved and recovery method fix\"\n",
        ")\n"
      ]
    }
  ]
}